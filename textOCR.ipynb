{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR and Embed with Azure Document Intelligence\n",
    "\n",
    "This notebook uses Azure Document Intelligence to perform OCR on a document and saves the results in JSON format.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we need to import the necessary libraries and load environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Set up Azure endpoint and key\n",
    "endpoint = os.getenv(\"AZURE_DI_ENDPOINT\")\n",
    "key = os.getenv(\"AZURE_DI_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Functions\n",
    "\n",
    "Next, we'll define helper functions that will be used to perform the OCR and process the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define function to get text from a document\n",
    "def get_document_text(document_path):\n",
    "    print(\"Starting OCR\")\n",
    "    document_intelligence_client = DocumentIntelligenceClient(\n",
    "        endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    "    )\n",
    "\n",
    "    with open(document_path, \"rb\") as f:\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            \"prebuilt-layout\", analyze_request=f, content_type=\"application/octet-stream\"\n",
    "        )\n",
    "    result: AnalyzeResult = poller.result()\n",
    "\n",
    "    paragraph_results = []\n",
    "    page_paragraph_count = {}\n",
    "    for paragraph in result.paragraphs:\n",
    "        if \"role\" not in paragraph and paragraph['spans'][0]['length'] >= 40:\n",
    "            page_number = paragraph.bounding_regions[0].page_number\n",
    "            if page_number not in page_paragraph_count:\n",
    "                page_paragraph_count[page_number] = 1\n",
    "            else:\n",
    "                page_paragraph_count[page_number] += 1\n",
    "            \n",
    "            paragraph_id = f\"{page_number}_{page_paragraph_count[page_number]}\"\n",
    "            paragraph_results.append({\n",
    "                'id': paragraph_id,\n",
    "                'page': page_number,\n",
    "                'content': paragraph.content,\n",
    "                'contentVector': []\n",
    "            })\n",
    "    print(\"Finished OCR\")\n",
    "    return paragraph_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution\n",
    "\n",
    "Now we can run the OCR process and save the results to a JSON file. For this example, specify the input and output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Run OCR on a PDF file and save the results to a JSON file\n",
    "# Specify input and output files\n",
    "input_file = 'demofile.pdf'  # Change the path to your input file\n",
    "output_file = 'textOCR.json'  # Change this to your desired output file name\n",
    "\n",
    "start_time = time.time()\n",
    "result = get_document_text(input_file)\n",
    "\n",
    "# Save result to JSON file\n",
    "with open(output_file, 'w') as json_file:\n",
    "    json.dump(result, json_file, indent=4)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
