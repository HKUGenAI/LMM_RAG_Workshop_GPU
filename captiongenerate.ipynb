{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captioning Images\n",
    "\n",
    "This notebook processes a JSON file of images, generates captions for each image, and computes embeddings for those captions using Azure OpenAI services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import os  \n",
    "import json  \n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv  \n",
    "import pandas as pd\n",
    "import time\n",
    "import traceback\n",
    "import base64  \n",
    "from mimetypes import guess_type  \n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the Azure OpenAI parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Set up the AzureOpenAI client\n",
    "api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  \n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")  \n",
    "deployment_name = 'trygpt4o'  \n",
    "api_version = '2024-02-01'  \n",
    "\n",
    "client = AzureOpenAI(  \n",
    "    api_key=api_key,  \n",
    "    api_version=api_version,  \n",
    "    base_url=f\"{api_base}/openai/deployments/{deployment_name}\"  \n",
    ")\n",
    "\n",
    "embedding_client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"EMBEDDING_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"EMBEDDING_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"EMBEDDING_OPENAI_API_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "We need some helper functions to handle image processing and data formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define functions to convert local image to data url and process data\n",
    "def local_image_to_data_url(image_path):  \n",
    "    mime_type, _ = guess_type(image_path)  \n",
    "    if mime_type is None:  \n",
    "        mime_type = 'application/octet-stream'  \n",
    "    with open(image_path, \"rb\") as image_file:  \n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')  \n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\"  \n",
    "\n",
    "def process_data(data, book_name):  \n",
    "    user_prompt = \"Find the associate caption for the cropped image from the whole_page image. If you cannot find the caption, make up a caption yourself by providing a detailed description of the image. Your response must be only the caption itself, do not respond anything other than this.\"\n",
    "    page_image_count = {}\n",
    "    for count, item in enumerate(data):\n",
    "        if data[count]['page'] not in page_image_count:\n",
    "            page_image_count[data[count]['page']] = 1\n",
    "        else:\n",
    "            page_image_count[data[count]['page']] += 1\n",
    "        data[count]['id'] = f\"{data[count]['page']}_{page_image_count[data[count]['page']]}\"\n",
    "        \n",
    "        messages = []  \n",
    "        user_content = []  \n",
    "        system_prompt = \"You are a helpful AI assistant.\"\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        \n",
    "        wholepage_url = local_image_to_data_url(book_name + \"_wholepageimage/\" + data[count]['image'].split(\"_img_\")[0] + \".png\")  \n",
    "        user_content.append({\"type\": \"image_url\", \"image_url\": {\"url\": wholepage_url , \"detail\": \"high\"}})  \n",
    "        user_content.append({\"type\": \"text\", \"text\": \"This is whole_page image\\n\"})  \n",
    "        \n",
    "        crop_url = local_image_to_data_url(book_name + \"_cropimage/\" + data[count]['image'])  \n",
    "        user_content.append({\"type\": \"image_url\", \"image_url\": {\"url\": crop_url , \"detail\": \"low\"}})  \n",
    "        user_content.append({\"type\": \"text\", \"text\": \"This is crop_image \" + user_prompt})  \n",
    "        messages.append({\"role\": \"user\", \"content\": user_content})  \n",
    "        \n",
    "        retry_count = 0\n",
    "        while retry_count < 2:\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=deployment_name,\n",
    "                    messages=messages,\n",
    "                    max_tokens=2000\n",
    "                )\n",
    "                response_text = response.choices[0].message.content\n",
    "                data[count]['caption'] = response_text\n",
    "                print(data[count], \"\\n\")\n",
    "                break\n",
    "            except (openai.BadRequestError, openai.InternalServerError) as e:\n",
    "                retry_count += 1\n",
    "                if retry_count == 2:\n",
    "                    print(f\"Error getting caption for {data[count]['image']} after retry\\n\")\n",
    "                    traceback.print_exc()\n",
    "                else:\n",
    "                    print(f\"Retrying to get caption for {data[count]['image']}\\n\")\n",
    "                    time.sleep(1)        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Data\n",
    "\n",
    "Let's load the input data and process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Process the data\n",
    "input_file = \"output/demofile.json\"  # replace with your actual file path\n",
    "output_file = \"imagecaption.json\"  # replace with your actual file path\n",
    "\n",
    "with open(input_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data = process_data(data, input_file.split(\".json\")[0])\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(f\"Processed data saved to {output_file}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "historian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
